import os
import io
import time
import json
import tempfile
from typing import Dict, Any, Optional

import pandas as pd
import streamlit as st

# å¤ç”¨å·²æœ‰é€»è¾‘
from p2p_evaluate import (
    EXCEL_PATH as DEFAULT_EXCEL_PATH,
    evaluate_row,
    predict_visual,
    predict_text,
    predict_visual_detail,
    predict_text_detail,
    fuse_visual_and_text,
    normalize_label,
)

# é¢„åŠ è½½å¿«é€Ÿè¯­éŸ³è½¬æ–‡æœ¬æ¨¡å‹
@st.cache_resource
def load_fast_stt_model():
    """é¢„åŠ è½½å¿«é€Ÿè¯­éŸ³è½¬æ–‡æœ¬æ¨¡å‹"""
    try:
        from stt_integration import get_fast_whisper_model
        model = get_fast_whisper_model()
        if model:
            st.success("âœ… å¿«é€Ÿè¯­éŸ³è½¬æ–‡æœ¬æ¨¡å‹åŠ è½½æˆåŠŸ")
            return model
        else:
            st.warning("âš ï¸ å¿«é€Ÿè¯­éŸ³è½¬æ–‡æœ¬æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
            return None
    except Exception as e:
        st.warning(f"âš ï¸ å¿«é€Ÿè¯­éŸ³è½¬æ–‡æœ¬æ¨¡å‹åŠ è½½å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
        return None

# å¿«é€Ÿè¯­éŸ³è½¬æ–‡æœ¬å‡½æ•°
def fast_transcribe_audio(audio_path: str) -> Optional[str]:
    """ä½¿ç”¨é¢„åŠ è½½çš„å¿«é€Ÿæ¨¡å‹è¿›è¡Œè¯­éŸ³è½¬æ–‡æœ¬"""
    if not audio_path or not os.path.exists(audio_path):
        return None
    
    # è·å–é¢„åŠ è½½çš„æ¨¡å‹
    model = st.session_state.get('fast_stt_model')
    if not model:
        # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨p2p_evaluateä¸­çš„å‡½æ•°
        from p2p_evaluate import transcribe_audio_to_text
        return transcribe_audio_to_text(audio_path)
    
    try:
        start_time = time.time()
        
        # ä½¿ç”¨ä¼˜åŒ–çš„å‚æ•°é…ç½®
        segments, info = model.transcribe(
            audio_path,
            beam_size=1,                    # æœ€å°beam sizeï¼Œæœ€å¿«é€Ÿåº¦
            language="zh",                  # æŒ‡å®šè¯­è¨€ï¼Œé¿å…æ£€æµ‹
            vad_filter=False,               # å…³é—­VADï¼Œæé«˜é€Ÿåº¦
            condition_on_previous_text=False, # ä¸ä¾èµ–å‰æ–‡
            temperature=0.0,                # ç¡®å®šæ€§è¾“å‡º
            word_timestamps=False           # å…³é—­æ—¶é—´æˆ³ï¼Œæé«˜é€Ÿåº¦
        )
        
        # æ‹¼æ¥æ‰€æœ‰åˆ†æ®µä¸ºä¸€æ¡å®Œæ•´å¥å­
        final_text = " ".join(seg.text.strip() for seg in segments if getattr(seg, "text", None))
        
        processing_time = time.time() - start_time
        st.info(f"ğŸµ è¯­éŸ³è½¬å†™å®Œæˆ ({processing_time:.2f}ç§’)")
        
        return final_text if final_text.strip() else None
        
    except Exception as e:
        st.error(f"âŒ è¯­éŸ³è½¬å†™å¤±è´¥: {e}")
        return None


def run_batch_auto_test(excel_path: str) -> Dict[str, Any]:
    if not os.path.exists(excel_path):
        raise FileNotFoundError(f"Excel æ–‡ä»¶ä¸å­˜åœ¨: {excel_path}")
    df = pd.read_excel(excel_path)
    required_cols = {"Picture", "Final_Label"}
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        raise ValueError(f"Excel ç¼ºå°‘å¿…è¦åˆ—: {missing}; ç°æœ‰åˆ—: {list(df.columns)}")

    records = []
    t0 = time.time()

    progress = st.progress(0.0, text="æ­£åœ¨è¯„ä¼°...")
    for idx, row in df.iterrows():
        result, refs = evaluate_row(row)
        data_id = row.get("ID", idx)
        records.append({"ID": data_id, **refs, **result})
        progress.progress((idx + 1) / len(df), text=f"{idx+1}/{len(df)}")

    elapsed = time.time() - t0
    total = len(records)
    correct = sum(1 for r in records if r["correct"]) if total else 0
    acc = correct / total if total else 0.0

    labels = sorted(["ANGRY", "HAPPY", "NEUTRAL", "SAD"])  # ä¸ VALID_LABELS ä¸€è‡´æ¬¡åº
    per_class = {}
    for lbl in labels:
        tp = sum(1 for r in records if r["true_label"] == lbl and r["fused_pred"] == lbl)
        actual = sum(1 for r in records if r["true_label"] == lbl)
        per_class[lbl] = (tp / actual) if actual > 0 else float("nan")

    row_times = [r["row_time_s"] for r in records]
    avg_time = sum(row_times) / len(row_times) if row_times else float("nan")
    p50_time = pd.Series(row_times).quantile(0.5) if row_times else float("nan")
    p95_time = pd.Series(row_times).quantile(0.95) if row_times else float("nan")

    return {
        "elapsed": elapsed,
        "total": total,
        "accuracy": acc,
        "per_class": per_class,
        "avg_time": avg_time,
        "p50_time": p50_time,
        "p95_time": p95_time,
        "records": records,
    }


def save_uploaded_file(uploaded_file, suffix: str) -> Optional[str]:
    if uploaded_file is None:
        return None
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        tmp.write(uploaded_file.read())
        return tmp.name


def run_single_test(image_path: Optional[str], audio_path: Optional[str], override_text: str = "") -> Dict[str, Any]:
    # 1) è§†è§‰ï¼ˆä½¿ç”¨è¯¦ç»†å‡½æ•°ï¼Œæ‹¿åˆ°åŸå› ä¸ç²¾ç¡®è€—æ—¶ï¼‰
    v_pred, v_reason, v_time = "NEUTRAL", "", 0.0
    if image_path and os.path.exists(image_path):
        v_pred, v_reason, v_time = predict_visual_detail(image_path)

    # 2) æ–‡æœ¬ï¼šè‹¥ override_text æä¾›åˆ™ä¼˜å…ˆä½¿ç”¨ï¼Œå¦åˆ™å°è¯•éŸ³é¢‘è½¬å†™
    asr_time = 0.0
    text_content = override_text.strip()
    if not text_content and audio_path and os.path.exists(audio_path):
        t0 = time.time()
        # ä½¿ç”¨æ–°çš„å¿«é€Ÿè¯­éŸ³è½¬æ–‡æœ¬åŠŸèƒ½
        text_from_asr = fast_transcribe_audio(audio_path)
        asr_time = time.time() - t0
        if text_from_asr:
            text_content = text_from_asr

    t_pred, t_reason, t_time = "NEUTRAL", "", 0.0
    if text_content:
        t_pred, t_reason, t_time = predict_text_detail(text_content)

    fused = fuse_visual_and_text(v_pred, t_pred)
    row_time = max(v_time, t_time, asr_time)
    return {
        "vision_pred": v_pred,
        "vision_reason": v_reason,
        "vision_time_s": v_time,
        "text_pred": t_pred,
        "text_reason": t_reason,
        "text_time_s": t_time,
        "asr_time_s": asr_time,
        "fused_pred": fused,
        "text_content": text_content,
        "row_time_s": row_time,
    }


APP_DIR = os.path.dirname(os.path.abspath(__file__))


def _ensure_abs_path(path: str) -> str:
    """Return absolute path; if relative, resolve relative to this file directory."""
    if not path:
        return path
    return path if os.path.isabs(path) else os.path.join(APP_DIR, path)


def main():
    st.set_page_config(page_title="å¤šæ¨¡æ€æƒ…ç»ªè¯†åˆ«æ¼”ç¤º", layout="wide")
    # å¼ºåˆ¶å¯ç”¨é¡µé¢æ»šåŠ¨ï¼ˆCloud æœ‰æ—¶å‡ºç° overflow é™åˆ¶ï¼‰
    st.markdown(
        """
        <style>
        html, body, [data-testid="stAppViewContainer"] { overflow: auto !important; }
        [data-testid="stVerticalBlock"] { overflow: visible !important; }
        </style>
        """,
        unsafe_allow_html=True,
    )
    st.title("å¤šæ¨¡æ€æƒ…ç»ªè¯†åˆ«æ¼”ç¤º")
    
    # åœ¨ç•Œé¢å¯åŠ¨æ—¶é¢„åŠ è½½è¯­éŸ³è½¬æ–‡æœ¬æ¨¡å‹
    with st.spinner("æ­£åœ¨åŠ è½½è¯­éŸ³è½¬æ–‡æœ¬æ¨¡å‹..."):
        fast_stt_model = load_fast_stt_model()
        # å°†æ¨¡å‹å­˜å‚¨åœ¨session_stateä¸­ï¼Œä¾›åç»­ä½¿ç”¨
        st.session_state['fast_stt_model'] = fast_stt_model
    
    st.success("ğŸš€ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")

    tab1, tab2 = st.tabs(["è‡ªåŠ¨æµ‹è¯•", "å•æ¡æµ‹è¯•ï¼ˆä¸Šä¼ å›¾ç‰‡ä¸éŸ³é¢‘ï¼‰"]) 

    with tab1:
        st.subheader("è‡ªåŠ¨æµ‹è¯•ï¼ˆæ‰¹é‡è¯„ä¼°ï¼‰")
        choice = st.radio("é€‰æ‹©æµ‹è¯•è§„æ¨¡", ["ç®€å•ï¼ˆ50æ¡ï¼‰", "å®Œæ•´ï¼ˆ196æ¡ï¼‰", "è‡ªå®šä¹‰è·¯å¾„"], horizontal=True)
        c1, c2, _ = st.columns([4, 1, 6])
        with c1:
            if choice == "ç®€å•ï¼ˆ50æ¡ï¼‰":
                excel_path = os.path.join(APP_DIR, "multimodal_emotion_data_50.xlsx")
                st.text_input("Excel è·¯å¾„", value=excel_path, disabled=True)
            elif choice == "å®Œæ•´ï¼ˆ196æ¡ï¼‰":
                excel_path = os.path.join(APP_DIR, "multimodal_emotion_data_196.xlsx")
                st.text_input("Excel è·¯å¾„", value=excel_path, disabled=True)
            else:
                default_path = _ensure_abs_path(DEFAULT_EXCEL_PATH)
                excel_path = st.text_input("Excel è·¯å¾„", value=default_path)
        with c2:
            run_btn = st.button("å¼€å§‹è‡ªåŠ¨æµ‹è¯•", type="primary")
        if run_btn:
            try:
                res = run_batch_auto_test(_ensure_abs_path(excel_path))
                st.success(f"æ ·æœ¬æ•°: {res['total']} | å‡†ç¡®ç‡: {res['accuracy']:.4f} | æ€»è€—æ—¶: {res['elapsed']:.2f}s | å¹³å‡å•æ¡: {res['avg_time']:.3f}s | 50åˆ†ä½: {res['p50_time']:.3f}s | 95åˆ†ä½: {res['p95_time']:.3f}s")

                st.write("æ¯ç±»å¬å›ç‡ï¼š")
                pc_df = pd.DataFrame({"label": list(res["per_class"].keys()), "recall": list(res["per_class"].values())})
                st.dataframe(pc_df, width='stretch', height=140)

                out_df = pd.DataFrame(res["records"]).sort_values("ID")
                st.dataframe(out_df, width='stretch', height=300)

                csv_bytes = out_df.to_csv(index=False).encode("utf-8-sig")
                st.download_button("ä¸‹è½½ç»“æœ CSV", data=csv_bytes, file_name="batch_results.csv", mime="text/csv")
            except Exception as e:
                st.error(f"æ‰¹é‡è¯„ä¼°å¤±è´¥: {e}")

    with tab2:
        st.subheader("å•æ¡æµ‹è¯•ï¼ˆä¸Šä¼ å›¾ç‰‡ä¸éŸ³é¢‘ï¼‰")
        
        # æ˜¾ç¤ºæ¨¡å‹çŠ¶æ€
        model_status = "âœ… å¿«é€Ÿæ¨¡å‹å·²åŠ è½½" if st.session_state.get('fast_stt_model') else "âš ï¸ ä½¿ç”¨å¤‡ç”¨æ¨¡å‹"
        st.info(f"è¯­éŸ³è½¬æ–‡æœ¬æ¨¡å‹çŠ¶æ€: {model_status}")
        
        col_left, col_right = st.columns([1,1])
        with col_left:
            img_file = st.file_uploader("ğŸ“· ä¸Šä¼ å›¾ç‰‡", type=["jpg", "jpeg", "png"])
            if img_file is not None:
                st.image(img_file, caption="ä¸Šä¼ çš„å›¾ç‰‡", width=280)
        with col_right:
            wav_file = st.file_uploader("ğŸµ ä¸Šä¼ éŸ³é¢‘", type=["wav", "mp3", "m4a", "flac"]) 
            override_text = st.text_area("ğŸ“ å¯é€‰ï¼šç›´æ¥è¾“å…¥æ–‡æœ¬ï¼ˆå°†è·³è¿‡è¯­éŸ³è½¬å†™ï¼‰", 
                                       placeholder="åœ¨è¿™é‡Œè¾“å…¥æ–‡æœ¬å†…å®¹...", 
                                       height=120)

        b1, b2, _ = st.columns([1,1,6])
        with b1:
            run_single_btn = st.button("ğŸš€ å¼€å§‹å•æ¡æµ‹è¯•", type="primary")
        if run_single_btn:
            with st.spinner("å¤„ç†ä¸­..."):
                tmp_img = save_uploaded_file(img_file, suffix=".png") if img_file else None
                tmp_wav = save_uploaded_file(wav_file, suffix=".wav") if wav_file else None

                try:
                    res = run_single_test(tmp_img, tmp_wav, override_text=override_text)
                finally:
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if tmp_img and os.path.exists(tmp_img):
                        try:
                            os.remove(tmp_img)
                        except Exception:
                            pass
                    if tmp_wav and os.path.exists(tmp_wav):
                        try:
                            os.remove(tmp_wav)
                        except Exception:
                            pass

            # å±•ç¤ºç»“æœ
            st.markdown("### ğŸ“Š é¢„æµ‹ç»“æœ")
            m1, m2, m3 = st.columns(3)
            m1.metric("ğŸ‘ï¸ è§†è§‰é¢„æµ‹", res["vision_pred"]) 
            m2.metric("ğŸ“ æ–‡æœ¬é¢„æµ‹", res["text_pred"]) 
            m3.metric("ğŸ¯ èåˆç»“æœ", res["fused_pred"]) 

            st.markdown("### ğŸ’¡ é¢„æµ‹åŸå› ")
            r1, r2 = st.columns(2)
            with r1:
                st.info(f"è§†è§‰åŸå› ï¼š{res.get('vision_reason','') or 'æ— '}")
            with r2:
                st.info(f"æ–‡æœ¬åŸå› ï¼š{res.get('text_reason','') or 'æ— '}")

            st.markdown("### â±ï¸ è€—æ—¶æƒ…å†µ")
            t1, t2, t3, t4 = st.columns(4)
            t1.metric("ğŸ‘ï¸ è§†è§‰ç”¨æ—¶", f"{res['vision_time_s']:.3f}s")
            t2.metric("ğŸµ ASRè½¬å†™", f"{res['asr_time_s']:.3f}s")
            t3.metric("ğŸ“ æ–‡æœ¬ç”¨æ—¶", f"{res['text_time_s']:.3f}s")
            t4.metric("âš¡ æ•´ä½“(å¹¶è¡Œ)", f"{res['row_time_s']:.3f}s")

            st.markdown("### ğŸµ è¯­éŸ³è½¬å†™æ–‡æœ¬")
            if res.get("text_content"):
                st.success(f"è½¬å†™ç»“æœ: {res['text_content']}")
            else:
                st.info("æ— è½¬å†™æ–‡æœ¬")


if __name__ == "__main__":
    main()


