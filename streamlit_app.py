import os
import io
import time
import json
import tempfile
from typing import Dict, Any, Optional

import pandas as pd
import streamlit as st
import base64
import requests
import sqlite3
import shutil
import uuid
try:
    from streamlit_mic_recorder import mic_recorder  # optional mic widget
except Exception:
    mic_recorder = None

# å¿…é¡»åœ¨ä»»ä½• Streamlit è°ƒç”¨å‰è®¾ç½®é¡µé¢é…ç½®ï¼Œé¿å… Cloud ä¸Šå¸ƒå±€/æ»šåŠ¨å¼‚å¸¸
st.set_page_config(page_title="å¤šæ¨¡æ€æƒ…ç»ªè¯†åˆ«æ¼”ç¤º", layout="wide")

# å°† Cloud Secrets æ³¨å…¥åˆ°ç¯å¢ƒå˜é‡ï¼Œä¾› REST å®¢æˆ·ç«¯è¯»å–
try:
    if "ARK_API_KEY" in st.secrets:
        os.environ["ARK_API_KEY"] = st.secrets["ARK_API_KEY"]
except Exception:
    pass

# å¤ç”¨å·²æœ‰é€»è¾‘
from p2p_evaluate import (
    EXCEL_PATH as DEFAULT_EXCEL_PATH,
    evaluate_row,
    predict_visual,
    predict_text,
    predict_visual_detail,
    predict_text_detail,
    fuse_visual_and_text,
    normalize_label,
)

# é¢„åŠ è½½å¿«é€Ÿè¯­éŸ³è½¬æ–‡æœ¬æ¨¡å‹
@st.cache_resource
def load_fast_stt_model():
    """é¢„åŠ è½½å¿«é€Ÿè¯­éŸ³è½¬æ–‡æœ¬æ¨¡å‹"""
    try:
        from stt_integration import get_fast_whisper_model
        model = get_fast_whisper_model()
        if model:
            st.success("âœ… å¿«é€Ÿè¯­éŸ³è½¬æ–‡æœ¬æ¨¡å‹åŠ è½½æˆåŠŸ")
            return model
        else:
            st.warning("âš ï¸ å¿«é€Ÿè¯­éŸ³è½¬æ–‡æœ¬æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
            return None
    except Exception as e:
        st.warning(f"âš ï¸ å¿«é€Ÿè¯­éŸ³è½¬æ–‡æœ¬æ¨¡å‹åŠ è½½å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
        return None

# å¿«é€Ÿè¯­éŸ³è½¬æ–‡æœ¬å‡½æ•°
def fast_transcribe_audio(audio_path: str) -> Optional[str]:
    """ä½¿ç”¨é¢„åŠ è½½çš„å¿«é€Ÿæ¨¡å‹è¿›è¡Œè¯­éŸ³è½¬æ–‡æœ¬"""
    if not audio_path or not os.path.exists(audio_path):
        return None
    
    # è·å–é¢„åŠ è½½çš„æ¨¡å‹
    model = st.session_state.get('fast_stt_model')
    if not model:
        # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨p2p_evaluateä¸­çš„å‡½æ•°
        from p2p_evaluate import transcribe_audio_to_text
        return transcribe_audio_to_text(audio_path)
    
    try:
        start_time = time.time()
        
        # ä½¿ç”¨ä¼˜åŒ–çš„å‚æ•°é…ç½®
        segments, info = model.transcribe(
            audio_path,
            beam_size=1,                    # æœ€å°beam sizeï¼Œæœ€å¿«é€Ÿåº¦
            language="zh",                  # æŒ‡å®šè¯­è¨€ï¼Œé¿å…æ£€æµ‹
            vad_filter=False,               # å…³é—­VADï¼Œæé«˜é€Ÿåº¦
            condition_on_previous_text=False, # ä¸ä¾èµ–å‰æ–‡
            temperature=0.0,                # ç¡®å®šæ€§è¾“å‡º
            word_timestamps=False           # å…³é—­æ—¶é—´æˆ³ï¼Œæé«˜é€Ÿåº¦
        )
        
        # æ‹¼æ¥æ‰€æœ‰åˆ†æ®µä¸ºä¸€æ¡å®Œæ•´å¥å­
        final_text = " ".join(seg.text.strip() for seg in segments if getattr(seg, "text", None))
        
        processing_time = time.time() - start_time
        st.info(f"ğŸµ è¯­éŸ³è½¬å†™å®Œæˆ ({processing_time:.2f}ç§’)")
        
        return final_text if final_text.strip() else None
        
    except Exception as e:
        hint = ""
        try:
            ext = os.path.splitext(audio_path)[1].lower()
            if ext in [".mp3", ".m4a", ".flac"]:
                hint = "ï¼ˆå¯èƒ½ç¼ºå°‘ ffmpegï¼Œå»ºè®®å®‰è£…åé‡è¯•ï¼Œæˆ–å…ˆè½¬ä¸º wavï¼‰"
        except Exception:
            pass
        st.error(f"âŒ è¯­éŸ³è½¬å†™å¤±è´¥: {e} {hint}")
        return None


def try_init_ark_sdk() -> None:
    """æ ¹æ® REST æ–¹æ¡ˆæ£€æŸ¥ Ark å¯ç”¨æ€§ï¼šåªè¦å­˜åœ¨ ARK_API_KEY å³è§†ä¸ºå¯ç”¨ã€‚"""
    if st.session_state.get('ark_initialized'):
        return
    api_key = os.environ.get("ARK_API_KEY")
    st.session_state['ark_available'] = bool(api_key)
    st.session_state['ark_initialized'] = True


def run_batch_auto_test(excel_path: str) -> Dict[str, Any]:
    if not os.path.exists(excel_path):
        raise FileNotFoundError(f"Excel æ–‡ä»¶ä¸å­˜åœ¨: {excel_path}")
    df = pd.read_excel(excel_path)
    required_cols = {"Picture", "Final_Label"}
    missing = [c for c in required_cols if c not in df.columns]
    if missing:
        raise ValueError(f"Excel ç¼ºå°‘å¿…è¦åˆ—: {missing}; ç°æœ‰åˆ—: {list(df.columns)}")

    records = []
    t0 = time.time()

    progress = st.progress(0.0, text="æ­£åœ¨è¯„ä¼°...")
    for idx, row in df.iterrows():
        result, refs = evaluate_row(row)
        data_id = row.get("ID", idx)
        records.append({"ID": data_id, **refs, **result})
        progress.progress((idx + 1) / len(df), text=f"{idx+1}/{len(df)}")

    elapsed = time.time() - t0
    total = len(records)
    correct = sum(1 for r in records if r["correct"]) if total else 0
    acc = correct / total if total else 0.0

    labels = sorted(["ANGRY", "HAPPY", "NEUTRAL", "SAD"])  # ä¸ VALID_LABELS ä¸€è‡´æ¬¡åº
    per_class = {}
    for lbl in labels:
        tp = sum(1 for r in records if r["true_label"] == lbl and r["fused_pred"] == lbl)
        actual = sum(1 for r in records if r["true_label"] == lbl)
        per_class[lbl] = (tp / actual) if actual > 0 else float("nan")

    row_times = [r["row_time_s"] for r in records]
    avg_time = sum(row_times) / len(row_times) if row_times else float("nan")
    p50_time = pd.Series(row_times).quantile(0.5) if row_times else float("nan")
    p95_time = pd.Series(row_times).quantile(0.95) if row_times else float("nan")

    return {
        "elapsed": elapsed,
        "total": total,
        "accuracy": acc,
        "per_class": per_class,
        "avg_time": avg_time,
        "p50_time": p50_time,
        "p95_time": p95_time,
        "records": records,
    }


def save_uploaded_file(uploaded_file, suffix: Optional[str] = None) -> Optional[str]:
    if uploaded_file is None:
        return None
    # ä¾æ®åŸæ–‡ä»¶åä¿ç•™æ‰©å±•åï¼Œé™¤éæ˜¾å¼ä¼ å…¥ suffix
    if suffix is None:
        try:
            _, ext = os.path.splitext(getattr(uploaded_file, "name", ""))
            suffix = ext if ext else ""
        except Exception:
            suffix = ""
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        tmp.write(uploaded_file.read())
        return tmp.name


def _file_to_base64(path: Optional[str], default_mime: str) -> Optional[Dict[str, str]]:
    if not path or not os.path.exists(path):
        return None
    try:
        _, ext = os.path.splitext(path)
        ext = (ext or "").lower()
        mime = default_mime
        if default_mime.startswith("image/"):
            if ext in [".png"]:
                mime = "image/png"
            elif ext in [".jpg", ".jpeg"]:
                mime = "image/jpeg"
        elif default_mime.startswith("audio/"):
            if ext in [".mp3"]:
                mime = "audio/mpeg"
            elif ext in [".m4a"]:
                mime = "audio/mp4"
            elif ext in [".flac"]:
                mime = "audio/flac"
            elif ext in [".wav"]:
                mime = "audio/wav"
        with open(path, "rb") as f:
            b64 = base64.b64encode(f.read()).decode("utf-8")
        return {"mime": mime, "data": b64}
    except Exception:
        return None


def upload_data_log(payload: Dict[str, Any]) -> None:
    """æ ¹æ®ç¯å¢ƒå˜é‡ LOG_TARGETS å†™å…¥å¤šç§è½ç›˜ç›®æ ‡ã€‚
    æ”¯æŒï¼š
      - http: ä½¿ç”¨ DATA_LOG_ENDPOINT POST
      - file: å†™å…¥ logs.ndjsonï¼Œå¹¶å°†åª’ä½“å¤åˆ¶åˆ° logs_media/
      - sqlite: å†™å…¥ logs.dbï¼Œå¹¶å°†åª’ä½“å¤åˆ¶åˆ° logs_media/
    é»˜è®¤ï¼šfile,sqlite
    """
    targets = (os.environ.get("LOG_TARGETS") or "file,sqlite").split(",")
    targets = [t.strip().lower() for t in targets if t.strip()]

    # å¤åˆ¶åª’ä½“åˆ°æœ¬åœ°ç›®å½•ï¼Œè¿”å›æ–°è·¯å¾„ï¼Œä¾¿äº file/sqlite å­˜å‚¨
    def _save_media_to_dir(tmp_path: Optional[str]) -> Optional[str]:
        if not tmp_path or not os.path.exists(tmp_path):
            return None
        try:
            os.makedirs("logs_media", exist_ok=True)
            _, ext = os.path.splitext(tmp_path)
            filename = f"{int(time.time())}_{uuid.uuid4().hex}{ext or ''}"
            dst = os.path.join("logs_media", filename)
            shutil.copyfile(tmp_path, dst)
            return dst
        except Exception:
            return None

    image_path = payload.get("__tmp_image_path")
    audio_path = payload.get("__tmp_audio_path")
    saved_image = _save_media_to_dir(image_path)
    saved_audio = _save_media_to_dir(audio_path)

    # æ„å»ºç®€åŒ–è®°å½•ï¼ˆåª’ä½“æ”¹ä¸ºæœ¬åœ°è·¯å¾„ï¼‰
    record = dict(payload)
    record.pop("media", None)
    record.pop("__tmp_image_path", None)
    record.pop("__tmp_audio_path", None)
    record["media_paths"] = {"image": saved_image, "audio": saved_audio}

    if "http" in targets:
        endpoint = os.environ.get("DATA_LOG_ENDPOINT")
        if endpoint:
            for _ in range(2):
                try:
                    resp = requests.post(endpoint, json=payload, timeout=20)
                    if 200 <= resp.status_code < 300:
                        break
                except Exception:
                    time.sleep(0.5)

    if "file" in targets:
        try:
            with open("logs.ndjson", "a", encoding="utf-8") as f:
                f.write(json.dumps(record, ensure_ascii=False) + "\n")
        except Exception:
            pass

    if "sqlite" in targets:
        try:
            conn = sqlite3.connect("logs.db")
            cur = conn.cursor()
            cur.execute(
                """
                CREATE TABLE IF NOT EXISTS logs (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp INTEGER,
                    user_mood TEXT,
                    user_note TEXT,
                    override_text TEXT,
                    result_json TEXT,
                    image_path TEXT,
                    audio_path TEXT
                )
                """
            )
            cur.execute(
                "INSERT INTO logs (timestamp, user_mood, user_note, override_text, result_json, image_path, audio_path) VALUES (?,?,?,?,?,?,?)",
                (
                    record.get("timestamp"),
                    record.get("user_mood"),
                    record.get("user_note"),
                    record.get("override_text"),
                    json.dumps(record.get("result"), ensure_ascii=False),
                    record["media_paths"].get("image"),
                    record["media_paths"].get("audio"),
                ),
            )
            conn.commit()
            conn.close()
        except Exception:
            pass


def init_local_logging_storage() -> None:
    """åˆå§‹åŒ–æœ¬åœ°æ—¥å¿—å­˜å‚¨ï¼Œé¿å…é¦–æ¬¡è¯»å–/å†™å…¥æ—¶æŠ¥æ–‡ä»¶ä¸å­˜åœ¨ã€‚"""
    try:
        # ç¡®ä¿åª’ä½“ç›®å½•å­˜åœ¨
        os.makedirs("logs_media", exist_ok=True)
        # ç¡®ä¿ NDJSON æ–‡ä»¶å­˜åœ¨
        if not os.path.exists("logs.ndjson"):
            with open("logs.ndjson", "a", encoding="utf-8") as _:
                pass
        # ç¡®ä¿ SQLite è¡¨å­˜åœ¨
        conn = sqlite3.connect("logs.db")
        cur = conn.cursor()
        cur.execute(
            """
            CREATE TABLE IF NOT EXISTS logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp INTEGER,
                user_mood TEXT,
                user_note TEXT,
                override_text TEXT,
                result_json TEXT,
                image_path TEXT,
                audio_path TEXT
            )
            """
        )
        conn.commit()
        conn.close()
    except Exception:
        pass


def _load_logs_from_sqlite(limit: int = 200, user_mood: Optional[str] = None, fused_pred: Optional[str] = None):
    if not os.path.exists("logs.db"):
        return None
    try:
        conn = sqlite3.connect("logs.db")
        base_sql = "SELECT id, timestamp, user_mood, user_note, override_text, result_json, image_path, audio_path FROM logs"
        conds = []
        params = []
        if user_mood:
            conds.append("user_mood = ?")
            params.append(user_mood)
        if fused_pred:
            conds.append("json_extract(result_json, '$.fused_pred') = ?")
            params.append(fused_pred)
        if conds:
            base_sql += " WHERE " + " AND ".join(conds)
        base_sql += " ORDER BY id DESC LIMIT ?"
        params.append(limit)
        df = pd.read_sql_query(base_sql, conn, params=params)
        conn.close()
        # å±•å¼€ result_json
        if not df.empty:
            res = df["result_json"].apply(lambda x: json.loads(x) if isinstance(x, str) and x else {})
            res_df = pd.json_normalize(res)
            df = pd.concat([df.drop(columns=["result_json"]), res_df], axis=1)
        return df
    except Exception:
        return None


def _load_logs_from_ndjson(limit: int = 200, user_mood: Optional[str] = None, fused_pred: Optional[str] = None):
    if not os.path.exists("logs.ndjson"):
        return None
    rows = []
    try:
        with open("logs.ndjson", "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    obj = json.loads(line)
                    rows.append(obj)
                except Exception:
                    continue
        if not rows:
            return None
        rows = rows[-limit:][::-1]
        df = pd.json_normalize(rows)
        # è¿‡æ»¤
        if user_mood:
            df = df[df.get("user_mood").fillna("") == user_mood]
        if fused_pred:
            df = df[df.get("result.fused_pred").fillna("") == fused_pred]
        return df
    except Exception:
        return None


def run_single_test(image_path: Optional[str], audio_path: Optional[str], override_text: str = "") -> Dict[str, Any]:
    # 1) è§†è§‰ï¼ˆä½¿ç”¨è¯¦ç»†å‡½æ•°ï¼Œæ‹¿åˆ°åŸå› ä¸ç²¾ç¡®è€—æ—¶ï¼‰
    v_pred, v_reason, v_time = "NEUTRAL", "", 0.0
    if image_path and os.path.exists(image_path):
        v_pred, v_reason, v_time = predict_visual_detail(image_path)

    # 2) æ–‡æœ¬ï¼šè‹¥ override_text æä¾›åˆ™ä¼˜å…ˆä½¿ç”¨ï¼Œå¦åˆ™å°è¯•éŸ³é¢‘è½¬å†™
    asr_time = 0.0
    text_content = override_text.strip()
    if not text_content and audio_path and os.path.exists(audio_path):
        t0 = time.time()
        # ä½¿ç”¨æ–°çš„å¿«é€Ÿè¯­éŸ³è½¬æ–‡æœ¬åŠŸèƒ½
        text_from_asr = fast_transcribe_audio(audio_path)
        asr_time = time.time() - t0
        if text_from_asr:
            text_content = text_from_asr

    t_pred, t_reason, t_time = "NEUTRAL", "", 0.0
    if text_content:
        t_pred, t_reason, t_time = predict_text_detail(text_content)

    fused = fuse_visual_and_text(v_pred, t_pred)
    row_time = max(v_time, t_time, asr_time)
    return {
        "vision_pred": v_pred,
        "vision_reason": v_reason,
        "vision_time_s": v_time,
        "text_pred": t_pred,
        "text_reason": t_reason,
        "text_time_s": t_time,
        "asr_time_s": asr_time,
        "fused_pred": fused,
        "text_content": text_content,
        "row_time_s": row_time,
    }


def main():
    st.title("å¤šæ¨¡æ€æƒ…ç»ªè¯†åˆ«æ¼”ç¤º")
    
    # åœ¨ç•Œé¢å¯åŠ¨æ—¶é¢„åŠ è½½ Ark SDK ä¸è¯­éŸ³è½¬æ–‡æœ¬æ¨¡å‹
    with st.spinner("æ­£åœ¨åŠ è½½ä¾èµ–ä¸æ¨¡å‹..."):
        init_local_logging_storage()
        try_init_ark_sdk()
        fast_stt_model = load_fast_stt_model()
        # å°†æ¨¡å‹å­˜å‚¨åœ¨session_stateä¸­ï¼Œä¾›åç»­ä½¿ç”¨
        st.session_state['fast_stt_model'] = fast_stt_model
    
    st.success("ğŸš€ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")

    # ç§»é™¤ UI å†…éƒ¨è®¾ç½® ARK_API_KEY çš„å…¥å£ï¼Œç»Ÿä¸€ä½¿ç”¨ç¯å¢ƒå˜é‡/Secrets

    tab1, tab2 = st.tabs(["è‡ªåŠ¨æµ‹è¯•", "å•æ¡æµ‹è¯•ï¼ˆä¸Šä¼ å›¾ç‰‡ä¸éŸ³é¢‘ï¼‰"]) 

    with tab1:
        st.subheader("è‡ªåŠ¨æµ‹è¯•ï¼ˆæ‰¹é‡è¯„ä¼°ï¼‰")
        choice = st.radio("é€‰æ‹©æµ‹è¯•è§„æ¨¡", ["ç®€å•ï¼ˆ50æ¡ï¼‰", "å®Œæ•´ï¼ˆ196æ¡ï¼‰", "è‡ªå®šä¹‰è·¯å¾„"], horizontal=True)
        c1, c2, _ = st.columns([4, 1, 6])
        with c1:
            if choice == "ç®€å•ï¼ˆ50æ¡ï¼‰":
                excel_path = os.path.join(".", "multimodal_emotion_data_50.xlsx")
                st.text_input("Excel è·¯å¾„", value=excel_path, disabled=True)
            elif choice == "å®Œæ•´ï¼ˆ196æ¡ï¼‰":
                excel_path = os.path.join(".", "multimodal_emotion_data_196.xlsx")
                st.text_input("Excel è·¯å¾„", value=excel_path, disabled=True)
            else:
                excel_path = st.text_input("Excel è·¯å¾„", value=DEFAULT_EXCEL_PATH)
        with c2:
            run_btn = st.button("å¼€å§‹è‡ªåŠ¨æµ‹è¯•", type="primary")
        if run_btn:
            try:
                res = run_batch_auto_test(excel_path)
                st.success(f"æ ·æœ¬æ•°: {res['total']} | å‡†ç¡®ç‡: {res['accuracy']:.4f} | æ€»è€—æ—¶: {res['elapsed']:.2f}s | å¹³å‡å•æ¡: {res['avg_time']:.3f}s | 50åˆ†ä½: {res['p50_time']:.3f}s | 95åˆ†ä½: {res['p95_time']:.3f}s")

                st.write("æ¯ç±»å¬å›ç‡ï¼š")
                pc_df = pd.DataFrame({"label": list(res["per_class"].keys()), "recall": list(res["per_class"].values())})
                st.dataframe(pc_df, use_container_width=True, height=140)

                out_df = pd.DataFrame(res["records"]).sort_values("ID")
                st.dataframe(out_df, use_container_width=True, height=300)

                csv_bytes = out_df.to_csv(index=False).encode("utf-8-sig")
                st.download_button("ä¸‹è½½ç»“æœ CSV", data=csv_bytes, file_name="batch_results.csv", mime="text/csv")
            except Exception as e:
                st.error(f"æ‰¹é‡è¯„ä¼°å¤±è´¥: {e}")

    with tab2:
        st.subheader("å•æ¡æµ‹è¯•ï¼ˆä¸Šä¼ å›¾ç‰‡ä¸éŸ³é¢‘ï¼‰")
        
        # æ˜¾ç¤ºæ¨¡å‹çŠ¶æ€
        model_status = "âœ… å¿«é€Ÿæ¨¡å‹å·²åŠ è½½" if st.session_state.get('fast_stt_model') else "âš ï¸ ä½¿ç”¨å¤‡ç”¨æ¨¡å‹"
        ark_status = "âœ… Ark å¯ç”¨" if st.session_state.get('ark_available') else "âš ï¸ Ark ä¸å¯ç”¨ï¼ˆä½¿ç”¨å›é€€ï¼‰"
        st.info(f"è¯­éŸ³è½¬æ–‡æœ¬æ¨¡å‹çŠ¶æ€: {model_status} | å¤§æ¨¡å‹: {ark_status}")
        
        # ä»…æ–‡æœ¬æ¨¡å¼å¯åœ¨å¼±ç½‘/ç§»åŠ¨ç«¯æ—¶è·³è¿‡è§†è§‰æ¨¡å‹
        only_text = st.checkbox("ä»…æ–‡æœ¬æ¨¡å¼ï¼ˆè·³è¿‡è§†è§‰è¯†åˆ«ï¼‰", value=False)

        col_left, col_right = st.columns([1,1])
        with col_left:
            img_file = st.file_uploader("ğŸ“· ä¸Šä¼ å›¾ç‰‡", type=["jpg", "jpeg", "png"])
            if img_file is not None:
                st.image(img_file, caption="ä¸Šä¼ çš„å›¾ç‰‡", width=280)
        with col_right:
            # å°†â€œä¸Šä¼ éŸ³é¢‘â€å’Œâ€œæˆ–è€…å½•éŸ³â€å¹¶æ’æ”¾ç½®
            a1, a2 = st.columns([1,1])
            with a1:
                wav_file = st.file_uploader("ğŸµ ä¸Šä¼ éŸ³é¢‘", type=["wav", "mp3", "m4a", "flac"]) 
            # å¯é€‰ï¼šä½¿ç”¨éº¦å…‹é£ç›´æ¥å½•éŸ³ï¼ˆä¸ä¸Šä¼ éŸ³é¢‘å¹¶æ’ï¼‰
            rec_tmp_path = None
            with a2:
                if mic_recorder is not None:
                    st.caption("æˆ–è€…å½•éŸ³")
                    rec = mic_recorder(start_prompt="å¼€å§‹å½•éŸ³", stop_prompt="åœæ­¢å½•éŸ³", format="wav", key="mic_recorder")
                    if rec and isinstance(rec, dict) and rec.get("bytes"):
                        st.audio(rec["bytes"])
                        try:
                            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmprec:
                                tmprec.write(rec["bytes"])
                                rec_tmp_path = tmprec.name
                        except Exception:
                            rec_tmp_path = None

            override_text = st.text_area("ğŸ“ å¯é€‰ï¼šç›´æ¥è¾“å…¥æ–‡æœ¬ï¼ˆå°†è·³è¿‡è¯­éŸ³è½¬å†™ï¼‰", 
                                       placeholder="åœ¨è¿™é‡Œè¾“å…¥æ–‡æœ¬å†…å®¹...", 
                                       height=120)

        # rec_tmp_path å·²åœ¨å³ä¾§åˆ—å†…è®¾ç½®ï¼ˆè‹¥ä½¿ç”¨å½•éŸ³ï¼‰

        b1, b2, _ = st.columns([1,1,6])
        with b1:
            run_single_btn = st.button("ğŸš€ å¼€å§‹å•æ¡æµ‹è¯•", type="primary")
        if run_single_btn:
            with st.spinner("å¤„ç†ä¸­..."):
                # ä¿ç•™ä¸Šä¼ å›¾ç‰‡åŸå§‹æ‰©å±•å
                tmp_img = save_uploaded_file(img_file) if img_file else None
                # å½•éŸ³ä¼˜å…ˆï¼Œå…¶æ¬¡æ˜¯ä¸Šä¼ æ–‡ä»¶
                if rec_tmp_path:
                    tmp_wav = rec_tmp_path
                else:
                    # ä¿ç•™ä¸Šä¼ éŸ³é¢‘åŸå§‹æ‰©å±•åï¼Œé¿å…ä»…é™ .wav
                    tmp_wav = save_uploaded_file(wav_file) if wav_file else None

                try:
                    # è°ƒè¯•ï¼šå±•ç¤ºæœåŠ¡å™¨ç«¯ä¿å­˜çš„ä¸´æ—¶æ–‡ä»¶è·¯å¾„ä¸å¤§å°ï¼Œå®šä½æ‰‹æœºç«¯è·¯å¾„ç›¸å…³é—®é¢˜
                    if tmp_img and os.path.exists(tmp_img):
                        st.caption(f"å›¾ç‰‡å·²ä¿å­˜: {tmp_img} ({os.path.getsize(tmp_img)} bytes)")
                    if tmp_wav and os.path.exists(tmp_wav):
                        st.caption(f"éŸ³é¢‘å·²ä¿å­˜: {tmp_wav} ({os.path.getsize(tmp_wav)} bytes)")
                    # è‹¥å‹¾é€‰ä»…æ–‡æœ¬æ¨¡å¼ï¼Œåˆ™ä¸ä¼ å›¾ç‰‡è·¯å¾„
                    img_arg = None if only_text else tmp_img
                    res = run_single_test(img_arg, tmp_wav, override_text=override_text)
                    # å°†ç»“æœä¸ä¸´æ—¶è·¯å¾„ä¿å­˜åˆ°ä¼šè¯ï¼Œä¾›ç»“æœé¡µä¸‹æ–¹äºŒæ¬¡ç¡®è®¤åå†å…¥åº“
                    st.session_state['last_result'] = res
                    st.session_state['last_tmp_image'] = tmp_img
                    st.session_state['last_tmp_audio'] = tmp_wav
                    st.session_state['last_override_text'] = override_text
                finally:
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    # ä¸ç«‹å³åˆ é™¤ï¼Œä»¥ä¾¿ç”¨æˆ·åœ¨ç»“æœé¡µé€‰æ‹©åä¿å­˜è®°å½•ã€‚
                    # å®é™…æ¸…ç†å‘ç”Ÿåœ¨â€œä¿å­˜è®°å½•â€åŠ¨ä½œä¹‹åã€‚
                    pass

        # æ— è®ºæ˜¯å¦ç‚¹å‡»æŒ‰é’®ï¼Œåªè¦ session_state æœ‰ç»“æœï¼Œå°±å±•ç¤ºå¹¶å…è®¸ä¿å­˜
        res = st.session_state.get('last_result')
        if res:
            st.markdown("### ğŸ“Š é¢„æµ‹ç»“æœ")
            m1, m2, m3 = st.columns(3)
            m1.metric("ğŸ‘ï¸ è§†è§‰é¢„æµ‹", res["vision_pred"]) 
            m2.metric("ğŸ“ æ–‡æœ¬é¢„æµ‹", res["text_pred"]) 
            m3.metric("ğŸ¯ èåˆç»“æœ", res["fused_pred"]) 

            st.markdown("### ğŸ’¡ é¢„æµ‹åŸå› ")
            r1, r2 = st.columns(2)
            with r1:
                st.info(f"è§†è§‰åŸå› ï¼š{res.get('vision_reason','') or 'æ— '}")
            with r2:
                st.info(f"æ–‡æœ¬åŸå› ï¼š{res.get('text_reason','') or 'æ— '}")

            st.markdown("### â±ï¸ è€—æ—¶æƒ…å†µ")
            t1, t2, t3, t4 = st.columns(4)
            t1.metric("ğŸ‘ï¸ è§†è§‰ç”¨æ—¶", f"{res['vision_time_s']:.3f}s")
            t2.metric("ğŸµ ASRè½¬å†™", f"{res['asr_time_s']:.3f}s")
            t3.metric("ğŸ“ æ–‡æœ¬ç”¨æ—¶", f"{res['text_time_s']:.3f}s")
            t4.metric("âš¡ æ•´ä½“(å¹¶è¡Œ)", f"{res['row_time_s']:.3f}s")

            st.markdown("### ğŸµ è¯­éŸ³è½¬å†™æ–‡æœ¬")
            if res.get("text_content"):
                st.success(f"è½¬å†™ç»“æœ: {res['text_content']}")
            else:
                st.info("æ— è½¬å†™æ–‡æœ¬")

            # ç»“æœä¹‹åå†è®©ç”¨æˆ·ç¡®è®¤å½“ä¸‹å¿ƒæƒ…å¹¶ä¿å­˜ï¼ˆåŠ æŒä¹… keyï¼Œé¿å…é€‰æ‹©ååˆ·æ–°ä¸¢å¤±ï¼‰
            st.markdown("### âœ… ä¿å­˜æœ¬æ¬¡è®°å½•")
            c1, c2 = st.columns([1,1])
            with c1:
                user_mood = st.selectbox("å½“ä¸‹å¿ƒæƒ…ï¼ˆè‡ªæŠ¥ï¼‰", ["", "ANGRY", "HAPPY", "SAD", "NEUTRAL"], index=0, key="user_mood_select")
            with c2:
                user_note = st.text_input("å¤‡æ³¨ï¼ˆå¯é€‰ï¼‰", placeholder="è¡¥å……è¯´æ˜â€¦", key="user_note_input")
            save_btn = st.button("ä¿å­˜è®°å½•")
            if save_btn:
                try:
                    payload = {
                        "timestamp": int(time.time()),
                        "user_mood": (st.session_state.get("user_mood_select") or None),
                        "user_note": (st.session_state.get("user_note_input") or None),
                        "override_text": st.session_state.get('last_override_text'),
                        "result": {
                            "vision_pred": res.get("vision_pred"),
                            "text_pred": res.get("text_pred"),
                            "fused_pred": res.get("fused_pred"),
                            "vision_time_s": res.get("vision_time_s"),
                            "text_time_s": res.get("text_time_s"),
                            "asr_time_s": res.get("asr_time_s"),
                            "row_time_s": res.get("row_time_s"),
                        },
                        "__tmp_image_path": st.session_state.get('last_tmp_image'),
                        "__tmp_audio_path": st.session_state.get('last_tmp_audio'),
                    }
                    upload_data_log(payload)
                    # ä¿å­˜åæ¸…ç†ä¸´æ—¶æ–‡ä»¶å¹¶æ¸…ç©ºä¼šè¯çŠ¶æ€
                    for k in ['last_tmp_image', 'last_tmp_audio']:
                        p = st.session_state.get(k)
                        if p and os.path.exists(p):
                            try:
                                os.remove(p)
                            except Exception:
                                pass
                    for k in ['last_result','last_tmp_image','last_tmp_audio','last_override_text','user_mood_select','user_note_input']:
                        if k in st.session_state:
                            del st.session_state[k]
                    st.success("å·²ä¿å­˜")
                except Exception as e:
                    st.warning(f"ä¿å­˜å¤±è´¥ï¼š{e}")

    

if __name__ == "__main__":
    main()


